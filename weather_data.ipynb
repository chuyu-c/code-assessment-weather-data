{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403654fc",
   "metadata": {},
   "source": [
    "Chuyu Chen  \n",
    "January 25, 2022  \n",
    "\n",
    "  \n",
    "Get any 7 consecutive days of weather data for your city (or any US city of your choice), as well as weather from Detroit, Michigan for the same period. The script should have the ability to run for a date. Have it load to S3/Google Cloud Storage (GCS) location. Share that location and the github code repo.\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "__Requirements:__\n",
    "1. Script should work when we git clone.\n",
    "2. Script pulls weather data and date/time from public rest-api's for Detroit and the\n",
    "additional city you chose. Load your results to S3/GCS.\n",
    "3. S3/GCS is accessible to us, you decide how we get access.\n",
    "4. Data in S3/GCS is formatted in a way that's easily loadable to a database table.\n",
    "5. Commands to load data from S3/GCS to postgres or mysql or redshift table or Bigquery\n",
    "and DDL for table.\n",
    "6. Ideally the goal is for us to easily query :\n",
    "select * from pubilc.weather_daily_table order by weather_date, location;\n",
    "7. Optional not required bonus: Publish the data to Tableau public or similar location.\n",
    "\n",
    "__References:__  \n",
    "* https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv\n",
    "* https://googleapis.dev/python/storage/latest/index.html  \n",
    "* https://github.com/visualcrossing/WeatherApi  \n",
    "* API: https://www.visualcrossing.com/weather-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e2979",
   "metadata": {},
   "source": [
    "### Pull data from public api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cae3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import requests, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f491fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter desired city names, follow by semicolon (eg. Detroit,MI;): Chicago,IL; New York,NY; Detroit,MI;\n",
      "Enter the first date of 7 consecutive days (in YYYY-MM-DD): 2021-01-01\n",
      "The corresponding end date is: 2021-01-08\n"
     ]
    }
   ],
   "source": [
    "#Downloading weather data using Python as a CSV using the Visual Crossing Weather API\n",
    "#See https://www.visualcrossing.com/resources/blog/how-to-load-historical-weather-data-using-python-without-scraping/ for more information.\n",
    "import csv\n",
    "import codecs\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import sys\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# core of weather query URL\n",
    "BaseURL = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/'\n",
    "\n",
    "# load ApiKey\n",
    "ApiKey=''\n",
    "\n",
    "# UnitGroup sets the units of the output - us or metric\n",
    "UnitGroup='us'\n",
    "\n",
    "# Prompt user input location city and state for the weather data\n",
    "# create a list including input cities and Detroit,MI\n",
    "# Location = ['Chicago,IL', 'Detroit,MI','Indianapolis,IN','Columbus,OH','Milwaukee,WI']\n",
    "\n",
    "Location = input(\"Enter desired city names, follow by semicolon (eg. Detroit,MI;): \")\n",
    "\n",
    "l = [item.replace(\" \",'') for item in Location.split(\";\")] \n",
    "if 'Detroit,MI' not in l:\n",
    "    l += ['Detroit,MI']\n",
    "if \"\" in l:\n",
    "    l.remove(\"\")\n",
    "Location = l\n",
    "\n",
    "\n",
    "\n",
    "# get 7 consecutive days of weather data in corresponding locations\n",
    "StartDate = input(\"Enter the first date of 7 consecutive days (in YYYY-MM-DD): \")\n",
    "EndDate=str(datetime.datetime.strptime(StartDate, \"%Y-%m-%d\") + timedelta(days=7)).split()[0]\n",
    "print(\"The corresponding end date is: \" + str(EndDate))\n",
    "\n",
    "#JSON or CSV \n",
    "#JSON format supports daily, hourly, current conditions, weather alerts and events in a single JSON package\n",
    "#CSV format requires an 'include' parameter below to indicate which table section is required\n",
    "ContentType=\"csv\"\n",
    "\n",
    "#include sections\n",
    "#values include days,hours,current,alerts\n",
    "Include=\"days\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb25d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chicago,IL', 'NewYork,NY', 'Detroit,MI']\n",
      "\n",
      " - Requesting weather for Chicago,IL: \n",
      " - Running query URL:  https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/Chicago,IL/2021-01-01/2021-01-08?&unitGroup=us&contentType=csv&include=days&key=VPCTK6KLC4VYY5WLKZRY6SK9T\n",
      "\n",
      "\n",
      " - Requesting weather for NewYork,NY: \n",
      " - Running query URL:  https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/NewYork,NY/2021-01-01/2021-01-08?&unitGroup=us&contentType=csv&include=days&key=VPCTK6KLC4VYY5WLKZRY6SK9T\n",
      "\n",
      "\n",
      " - Requesting weather for Detroit,MI: \n",
      " - Running query URL:  https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/Detroit,MI/2021-01-01/2021-01-08?&unitGroup=us&contentType=csv&include=days&key=VPCTK6KLC4VYY5WLKZRY6SK9T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "print(Location)\n",
    "for i in Location:\n",
    "    print('')\n",
    "    print(f' - Requesting weather for {i}: ')\n",
    "    \n",
    "    #basic query including location\n",
    "    ApiQuery=BaseURL + i\n",
    "\n",
    "    #append the start and end date if present\n",
    "    if (len(StartDate)):\n",
    "        ApiQuery+=\"/\"+StartDate\n",
    "        if (len(EndDate)):\n",
    "            ApiQuery+=\"/\"+EndDate\n",
    "\n",
    "    #Url is completed. Now add query parameters (could be passed as GET or POST)\n",
    "    ApiQuery+=\"?\"\n",
    "\n",
    "    #append each parameter as necessary\n",
    "    if (len(UnitGroup)):\n",
    "        ApiQuery+=\"&unitGroup=\"+UnitGroup\n",
    "\n",
    "    if (len(ContentType)):\n",
    "        ApiQuery+=\"&contentType=\"+ContentType\n",
    "\n",
    "    if (len(Include)):\n",
    "        ApiQuery+=\"&include=\"+Include\n",
    "\n",
    "    ApiQuery+=\"&key=\"+ApiKey\n",
    "\n",
    "\n",
    "\n",
    "    print(' - Running query URL: ', ApiQuery)\n",
    "    print()\n",
    "\n",
    "    try: \n",
    "        CSVBytes = urllib.request.urlopen(ApiQuery)\n",
    "    except urllib.error.HTTPError  as e:\n",
    "        ErrorInfo= e.read().decode() \n",
    "        print('Error code: ', e.code, ErrorInfo)\n",
    "        sys.exit()\n",
    "    except  urllib.error.URLError as e:\n",
    "        ErrorInfo= e.read().decode() \n",
    "        print('Error code: ', e.code,ErrorInfo)\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "    # Parse the results as CSV\n",
    "    CSVText = csv.reader(codecs.iterdecode(CSVBytes, 'utf-8'))\n",
    "\n",
    "    RowIndex = 0\n",
    "\n",
    "    # The first row contain the headers and the additional rows each contain the weather metrics for a single day\n",
    "    # To simply our code, we use the knowledge that column 0 contains the location and column 1 contains the date.  The data starts at column 4\n",
    "    for Row in CSVText:\n",
    "        if RowIndex == 0:\n",
    "            FirstRow = Row\n",
    "            columns = Row\n",
    "        else:\n",
    "            data.append(Row)\n",
    "            #print('Weather in ', Row[0], ' on ', Row[1])\n",
    "\n",
    "            ColIndex = 0\n",
    "            for Col in Row:\n",
    "                if ColIndex >= 4:\n",
    "                    continue\n",
    "                    #print('   ', FirstRow[ColIndex], ' = ', Row[ColIndex])\n",
    "                ColIndex += 1\n",
    "        RowIndex += 1\n",
    "\n",
    "    # If there are no CSV rows then something fundamental went wrong\n",
    "    if RowIndex == 0:\n",
    "        print('Sorry, but it appears that there was an error connecting to the weather server.')\n",
    "        print('Please check your network connection and try again..')\n",
    "\n",
    "    # If there is only one CSV  row then we likely got an error from the server\n",
    "    if RowIndex == 1:\n",
    "        print('Sorry, but it appears that there was an error retrieving the weather data.')\n",
    "        print('Error: ', FirstRow)\n",
    "\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14703eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ceb019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'datetime', 'tempmax', 'tempmin', 'temp', 'feelslikemax',\n",
       "       'feelslikemin', 'feelslike', 'dew', 'humidity', 'precip', 'precipprob',\n",
       "       'precipcover', 'preciptype', 'snow', 'snowdepth', 'windgust',\n",
       "       'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility',\n",
       "       'solarradiation', 'solarenergy', 'uvindex', 'severerisk', 'sunrise',\n",
       "       'sunset', 'moonphase', 'conditions', 'description', 'icon', 'stations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d6debbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4909efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a python dataframe with weather data\n",
    "\n",
    "df = pd.DataFrame(data, columns = columns)\n",
    "df[[\"City\", \"State\", \"Country\"]] = df[\"name\"].str.split(pat=\",\", expand=True)\n",
    "\n",
    "df1 = df\n",
    "cols = list(df.columns)\n",
    "cols = cols[-3:] + cols[:-3]\n",
    "df = df[cols]\n",
    "\n",
    "# only include 13 columns for our purposes\n",
    "df = df.iloc[:, : 11]\n",
    "df['conditions'] = df1['conditions']\n",
    "df['description'] = df1['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a541b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c32d0",
   "metadata": {},
   "source": [
    "### Load data to Google Cloud Storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706a5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcloud import storage\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e21fd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "credentials_dict = {\n",
    "  \"type\": \"service_account\",\n",
    "  \"project_id\": \"nimble-net-337716\",\n",
    "  \"private_key_id\": \"5ea5e115ddb0e068eb21996d2334ee942b9c7a68\",\n",
    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvwIBADANBgkqhkiG9w0BAQEFAASCBKkwggSlAgEAAoIBAQC5VLAazQ9Szpnf\\n/d1bag3Heg3rRt45039yW8n5UYOac7qcJ/jcTeLMPVcpZsQVc7urEPPJY24w2sbQ\\n6RCbbWLVdJG2cILpy9j6mWEnVXj6WF3HkpnZdpFMrJdDfrAPWCZS5zlsr9iLTIuZ\\nq8BBo6ue48/OnT+Bbo5640pJTF5K8YMw07r0Pl83JTJ9QRqrZh07eQKdZyP+K/Wh\\nBA9/GG6zT65jMX7drHGRP0FXUdAAcDTY9k5dqHBpd1Nxe5qw1NtUAKNcK59gHhjg\\niA1wyjKkdXf31pijdARYff0sPSHdqLld1x0pIb1JSiXORjcoow3ERU/zFBpHku/2\\nOyfdBqmvAgMBAAECggEAFF4ozoE7zmNzSMkrIylII2SYFAPhV2SVjJlm3JYnSvmu\\nCAxijr+mjcCuDBhFs3/ZH6dIy5i4WvkoQXxjvVkrs/7QJsc9s/kZuwzRPxPnLEg6\\n4jyL2PjtZgpPw3SwX7dV2uWbi4TV3RVIAFb+VZhpu5gY1gG1IYHnebzyBJU2hbDO\\nRRWhhEkspZSuMTsTzyS9M/eEiv8YTpWlor/1V/WV2Uk0syBntTXtyRWM3QfRXPq/\\nDpc0J6PHpCR9IAT7XcNwCZIAujL4mjZRzsF3ufC7J17ovq91ukl8njC9+E/ADCKv\\nT0iQewgZfm2upf2u26lhtLBm9fLPnmC96VEzQDggMQKBgQDk6BhllLo7d88bueZ4\\nxXqTmTT/odecSi6Euxgeh+l3sZsi/9+XRPvg70CfzZHsKVAAgaKAH80HnGm6uO0Z\\nd6+seIHcm3FCBv5c14bmsfB7NqtemvZj9eB81gQCGEoq7QVrokCXOKpEY/ESxFIQ\\nRTgYkX/Y6vN46bbzTw79+xS/kQKBgQDPRD00bXE7qK8CIiftuMK9Tm3dCi6KJjEm\\nB68x0Swp7Uiiw3p3IjOYXOwY2pGCh7xzfUvIK1dkU0cGXxcwtYkjPAd3Cj34bzeD\\nILhFR8g+YgEv27jl585kbBbYVSCkhPOUdwMG+b2ZHWSxu7GMnllMK4jSqt7EMTjV\\nUoW65tq1PwKBgQC/nwN9Vcmoqpz3quGiTD5WfLR/Iq5pqTfT6QNB26i3iDhETkqQ\\nSTFJlT9WBzKWrebI5bxw4S4zpt5jbxcccLLhAGhFkuJ20X/xnILTcDXOD2/Z3INS\\nHqx0FHx6fHbqBEy7U7IaZVcztS5D9ZB1ClzxRCvwHI8AszVx7MayGpO94QKBgQCp\\nQwD4n6epIMhK5bnV2Nyv3Cy8JmR7TVU1yXC5Lijy1GRNB3YrdDLOapQkd9n8zvyH\\nE/ufLEXiGGAYQ++cR6QGsi8md6bEC4859q6FZWmSCFcPzk/g8L0MJXlCkcJmmGyT\\nAd3nBGxhbi+dNbp5K5ehLKw/3mqtrcTL8OhlCcHx4QKBgQDTbTrpVidBgCutSyRS\\nojTCQXVBhHnbd2zlQYizF5dSJ5aliuGLraSvahL7Y4s4Ye1ytm1H9QaZbNkqINl2\\nh6tl9LxU/ccvk7IFZwo2OcBn4woBHdS9yW4De/Tb4zAWOMOgepbZSVZ75MKB4rPt\\niW4T+CBD47DAlM0td6cgh6Z2vw==\\n-----END PRIVATE KEY-----\\n\",\n",
    "  \"client_email\": \"weather-data@nimble-net-337716.iam.gserviceaccount.com\",\n",
    "  \"client_id\": \"112657965371709403967\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/weather-data%40nimble-net-337716.iam.gserviceaccount.com\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_dict(\n",
    "    credentials_dict\n",
    ")\n",
    "\n",
    "client = storage.Client(credentials=credentials, project='nimble-net-337716')\n",
    "bucket = client.get_bucket('weather-data-cc')\n",
    "blob = bucket.blob(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e869506",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.blob('weather.csv').upload_from_string(df.to_csv(index=False), 'text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74886da7",
   "metadata": {},
   "source": [
    "### Load data from GCS to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb83b595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   City          24 non-null     object\n",
      " 1   State         24 non-null     object\n",
      " 2   Country       24 non-null     object\n",
      " 3   name          24 non-null     object\n",
      " 4   datetime      24 non-null     object\n",
      " 5   tempmax       24 non-null     object\n",
      " 6   tempmin       24 non-null     object\n",
      " 7   temp          24 non-null     object\n",
      " 8   feelslikemax  24 non-null     object\n",
      " 9   feelslikemin  24 non-null     object\n",
      " 10  feelslike     24 non-null     object\n",
      " 11  conditions    24 non-null     object\n",
      " 12  description   24 non-null     object\n",
      "dtypes: object(13)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c8467c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get credential key file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"nimble-net-337716-5ea5e115ddb0.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3809508",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 48 rows.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set table_id to the ID of the table to create.\n",
    "table_id = \"nimble-net-337716.public.weather_daily_table\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"City\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"State\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"Country\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"tempmax\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"tempmin\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"temp\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"feelslikemax\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"feelslikemin\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"feelslike\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"conditions\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"description\", \"STRING\")\n",
    "    ],\n",
    "    skip_leading_rows=1,\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "uri = \"gs://weather-data-cc/weather.csv\"\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = client.get_table(table_id)  # Make an API request.\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd19df62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       City State         Country                         name   datetime  \\\n",
      "0   Chicago    IL   United States   Chicago, IL, United States 2021-01-01   \n",
      "1   Chicago    IL   United States   Chicago, IL, United States 2021-01-01   \n",
      "2   Detroit    MI   United States   Detroit, MI, United States 2021-01-01   \n",
      "3   Detroit    MI   United States   Detroit, MI, United States 2021-01-01   \n",
      "4  New York    NY   United States  New York, NY, United States 2021-01-01   \n",
      "\n",
      "   tempmax  tempmin  temp  feelslikemax  feelslikemin  feelslike  \\\n",
      "0     35.2     24.0  30.8          27.3          17.2       22.3   \n",
      "1     35.2     24.0  30.8          27.3          17.2       22.3   \n",
      "2     33.4     22.6  29.5          26.3          17.5       22.7   \n",
      "3     33.4     22.6  29.5          26.3          17.5       22.7   \n",
      "4     39.1     33.5  36.5          35.9          28.0       31.7   \n",
      "\n",
      "               conditions                                  description  \n",
      "0          Snow, Overcast   Cloudy skies throughout the day with rain.  \n",
      "1          Snow, Overcast   Cloudy skies throughout the day with rain.  \n",
      "2  Snow, Partially cloudy  Partly cloudy throughout the day with snow.  \n",
      "3  Snow, Partially cloudy  Partly cloudy throughout the day with snow.  \n",
      "4  Rain, Partially cloudy  Becoming cloudy in the afternoon with rain.  \n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "bqclient = bigquery.Client()\n",
    "\n",
    "# Download query results.\n",
    "query_string = \"\"\"\n",
    "SELECT *\n",
    "FROM `nimble-net-337716.public.weather_daily_table`\n",
    "ORDER BY datetime,City\n",
    "\"\"\"\n",
    "\n",
    "dataframe = (\n",
    "    bqclient.query(query_string)\n",
    "    .result()\n",
    "    .to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    ")\n",
    "print(dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95328aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b37d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
